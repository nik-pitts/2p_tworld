{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src.tile_definitions import TILE_MAPPING\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameDataset(Dataset):\n",
    "    def __init__(self, json_file):\n",
    "        with open(json_file, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        \n",
    "        # Action to integer mapping\n",
    "        self.action_mapping = {\"UP\": 0, \"DOWN\": 1, \"LEFT\": 2, \"RIGHT\": 3}\n",
    "\n",
    "        # Create reverse mapping (tile_type -> ID) from TILE_MAPPING\n",
    "        self.tile_type_to_id = {}\n",
    "        for tile_id, (tile_type, _, _, _, _) in TILE_MAPPING.items():\n",
    "            self.tile_type_to_id[tile_type] = tile_id\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        state = sample[\"state\"]\n",
    "        action = self.action_mapping[sample[\"action\"]]\n",
    "        \n",
    "        # Extract state components\n",
    "        position = torch.tensor(state[\"position\"], dtype=torch.float32)\n",
    "        chips_collected = torch.tensor([state[\"player_collected_chips\"]], dtype=torch.float32)\n",
    "        total_chips_collected = torch.tensor([state[\"total_collected_chips\"]], dtype=torch.float32)\n",
    "        socket_unlocked = torch.tensor([int(state[\"socket_unlocked\"])], dtype=torch.float32)\n",
    "        nearest_chip = torch.tensor(state[\"nearest_chip\"], dtype=torch.float32)\n",
    "        exit_location = torch.tensor(state[\"exit_position\"], dtype=torch.float32)\n",
    "        \n",
    "        # Process the full grid\n",
    "        full_grid = []\n",
    "        for row in state[\"full_grid\"]:\n",
    "            processed_row = []\n",
    "            for tile_type in row:\n",
    "                # Map to integer using the updated tile definitions\n",
    "                processed_row.append(self.tile_type_to_id.get(tile_type, 1))\n",
    "            full_grid.append(processed_row)\n",
    "        \n",
    "        full_grid_tensor = torch.tensor(full_grid, dtype=torch.float32)\n",
    "        \n",
    "        # Additional state information\n",
    "        is_sliding = torch.tensor([float(state.get(\"is_sliding\", False))], dtype=torch.float32)\n",
    "        is_being_forced = torch.tensor([float(state.get(\"is_being_forced\", False))], dtype=torch.float32)\n",
    "        alive = torch.tensor([float(state.get(\"alive\", True))], dtype=torch.float32)\n",
    "        remaining_chips = torch.tensor([state.get(\"remaining_chips\", 0)], dtype=torch.float32)\n",
    "        other_player_pos = torch.tensor(state.get(\"other_player_position\", [-1, -1]), dtype=torch.float32)\n",
    "        \n",
    "        # Concatenate all state information into a single vector\n",
    "        state_vector = torch.cat([\n",
    "            position,\n",
    "            chips_collected, \n",
    "            total_chips_collected,\n",
    "            socket_unlocked,\n",
    "            nearest_chip,\n",
    "            exit_location,\n",
    "            full_grid_tensor.flatten(),\n",
    "            is_sliding,\n",
    "            is_being_forced,\n",
    "            alive,\n",
    "            remaining_chips,\n",
    "            other_player_pos\n",
    "        ])\n",
    "        \n",
    "        return state_vector, torch.tensor(action, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¢ Sample Vector: torch.Size([184])\n",
      "üìä Loaded 646 samples.\n"
     ]
    }
   ],
   "source": [
    "dataset = GameDataset(\"../data/human_play_data_level0.json\")\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "sample_vector, sample_action = dataset[0]  \n",
    "print(f\"üî¢ Sample Vector: {sample_vector.size()}\")  # üî• ÏÉòÌîå Î≤°ÌÑ∞ ÌÅ¨Í∏∞ ÌôïÏù∏!\n",
    "print(f\"üìä Loaded {len(dataset)} samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior Cloning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNC Network for behavior cloning\n",
    "class BehaviorCloningModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(BehaviorCloningModel, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(),                          \n",
    "            nn.Linear(256, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([  2.,   6.,   0.,   0.,   0.,   3.,   3.,   6.,   6.,   1.,   1.,   1.,\n",
      "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   0.,\n",
      "          0.,   0.,   0.,   0.,  47.,   0.,   0.,   0.,   0.,   0.,   1.,   1.,\n",
      "          0.,   0.,   4.,   1.,   0.,   0.,   0.,   1.,   3.,   0.,   0.,   1.,\n",
      "          1.,   0.,   0., 200.,   1.,   0.,   0.,   0.,   1., 201.,   0.,   0.,\n",
      "          1.,   1.,   0.,   1.,   1.,   1.,   0.,   0.,   0.,   1.,   1.,   1.,\n",
      "          0.,   1.,   1.,   0.,   0.,   0.,   0.,   0.,  34.,   0.,   0.,   0.,\n",
      "          0.,   0.,   1.,   1.,   0.,   0.,   0.,   0.,  34.,  21.,  34.,   0.,\n",
      "          0.,   0.,   0.,   1.,   1.,   0.,   0.,   0.,   0.,   0.,  34.,   0.,\n",
      "          0.,   0.,   0.,   0.,   1.,   1.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.,   0.,   0.,   1.,   1.,   0.,   1.,   1.,   1.,   0.,\n",
      "          0.,   0.,   1.,   1.,   1.,   0.,   1.,   1.,   0.,   3., 202.,   1.,\n",
      "          0.,   0.,   0.,   1., 203.,   4.,   0.,   1.,   1.,   0.,   0.,   0.,\n",
      "          1.,   0.,   0.,   0.,   1.,   0.,   0.,   0.,   1.,   1.,   1.,   1.,\n",
      "          1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   1.,   0.,   0.,\n",
      "          1.,   4.,  11.,   7.]), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "input_size = len(dataset[0][0])  # Size of State Vector\n",
    "print(dataset[0])\n",
    "output_size = 4  # Possible Actions (UP, DOWN, LEFT, RIGHT)\n",
    "model = BehaviorCloningModel(input_size, output_size)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size 184, output_size: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"input_size {input_size}, output_size: {output_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# traning configuration\n",
    "training_config = {\n",
    "    \"epochs\": 2000,\n",
    "    \"model_name\": \"BehaviorCloningModel\",\n",
    "    \"intput_size\": input_size,\n",
    "    \"output_size\": output_size,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"batch_size\": 128,\n",
    "    \"criterion\": \"CrossEntropyLoss\",\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"scheudler\": \"StepLR\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/neo/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/neo/gym-workspace/2p_tworld/colab/wandb/run-20250305_191651-whole_256_FCN-3Layer_2000ep_4</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner/runs/whole_256_FCN-3Layer_2000ep_4' target=\"_blank\">mar_05</a></strong> to <a href='https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner' target=\"_blank\">https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner/runs/whole_256_FCN-3Layer_2000ep_4' target=\"_blank\">https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner/runs/whole_256_FCN-3Layer_2000ep_4</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"294ac5de6babc54da53b9aadb344b3bb173b314d\")\n",
    "# change name for each run\n",
    "wandb.init(project=\"bc_surrogate_partner\", name=\"mar_05\", id=\"whole_256_FCN-3Layer_2000ep_4\", resume=\"never\")\n",
    "wandb.config.update(training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/2000, Loss: 0.1162, LR: 0.0003\n",
      "Epoch 200/2000, Loss: 0.0595, LR: 0.0003\n",
      "Epoch 300/2000, Loss: 0.0619, LR: 0.0003\n",
      "Epoch 400/2000, Loss: 0.0616, LR: 0.0003\n",
      "Epoch 500/2000, Loss: 0.0739, LR: 0.0003\n",
      "Epoch 600/2000, Loss: 0.0493, LR: 0.0003\n",
      "Epoch 700/2000, Loss: 0.1809, LR: 0.0003\n",
      "Epoch 800/2000, Loss: 0.0524, LR: 0.0002\n",
      "Epoch 900/2000, Loss: 0.0442, LR: 0.0002\n",
      "Epoch 1000/2000, Loss: 0.0442, LR: 0.0002\n",
      "Epoch 1100/2000, Loss: 0.0872, LR: 0.0002\n",
      "Epoch 1200/2000, Loss: 0.0368, LR: 0.0002\n",
      "Epoch 1300/2000, Loss: 0.0376, LR: 0.0002\n",
      "Epoch 1400/2000, Loss: 0.0372, LR: 0.0002\n",
      "Epoch 1500/2000, Loss: 0.0407, LR: 0.0002\n",
      "Epoch 1600/2000, Loss: 0.0381, LR: 0.0002\n",
      "Epoch 1700/2000, Loss: 0.0350, LR: 0.0002\n",
      "Epoch 1800/2000, Loss: 0.0432, LR: 0.0001\n",
      "Epoch 1900/2000, Loss: 0.0544, LR: 0.0001\n",
      "Epoch 2000/2000, Loss: 0.0357, LR: 0.0001\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>learning_rate</td><td>‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>loss</td><td>‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>2000</td></tr><tr><td>learning_rate</td><td>0.00012</td></tr><tr><td>loss</td><td>0.03569</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mar_05</strong> at: <a href='https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner/runs/whole_256_FCN-3Layer_2000ep_4' target=\"_blank\">https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner/runs/whole_256_FCN-3Layer_2000ep_4</a><br> View project at: <a href='https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner' target=\"_blank\">https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250305_191651-whole_256_FCN-3Layer_2000ep_4/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# üî• ÌõàÎ†® Î£®ÌîÑ\n",
    "num_epochs = training_config[\"epochs\"]\n",
    "scheduler = StepLR(optimizer, step_size=200, gamma=0.9)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "\n",
    "    for state_vector, action in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # predict\n",
    "        outputs = model(state_vector)\n",
    "\n",
    "        # loss calculation\n",
    "        loss = criterion(outputs, action)\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # back propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, LR: {scheduler.get_last_lr()[0]:.4f}\")\n",
    "        wandb.log({\"epoch\": epoch + 1, \"loss\": avg_loss, \"learning_rate\": scheduler.get_last_lr()[0]})\n",
    "        \n",
    "# close wandb\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model save directory\n",
    "model_path = \"../model/lv1_bc_model_2.1.pth\"\n",
    "# Save model\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Predicted Action: DOWN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jk/fgtqjbt14jg00g8k4jkjl6_40000gn/T/ipykernel_92534/3803181024.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state_vector = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n"
     ]
    }
   ],
   "source": [
    "def predict_action(model, state):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        state_vector = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "        output = model(state_vector)\n",
    "        action_idx = torch.argmax(output).item()\n",
    "    \n",
    "    action_mapping = {0: \"UP\", 1: \"DOWN\", 2: \"LEFT\", 3: \"RIGHT\"}\n",
    "    return action_mapping[action_idx]\n",
    "\n",
    "test_state, _ = dataset[5]  # Check the first sample in the dataset\n",
    "predicted_action = predict_action(model, test_state)\n",
    "print(f\"AI Predicted Action: {predicted_action}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
