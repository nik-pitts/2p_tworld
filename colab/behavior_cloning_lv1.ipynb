{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import os\n",
    "# Add the parent directory to sys.path\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "from src.tile_definitions import TILE_MAPPING\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Level1GameDataset(Dataset):\n",
    "    def __init__(self, json_file):\n",
    "        with open(json_file, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "            \n",
    "        print(f\"Loaded {len(self.data)} gameplay samples from {json_file}\")\n",
    "        \n",
    "        # Action to integer mapping\n",
    "        self.action_mapping = {\"UP\": 0, \"DOWN\": 1, \"LEFT\": 2, \"RIGHT\": 3}\n",
    "\n",
    "        # Create reverse mapping (tile_type -> ID) from TILE_MAPPING\n",
    "        self.tile_type_to_id = {}\n",
    "        for tile_id, (tile_type, _, _, _, _) in TILE_MAPPING.items():\n",
    "            self.tile_type_to_id[tile_type] = tile_id\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        state = sample[\"state\"]\n",
    "        action = self.action_mapping[sample[\"action\"]]\n",
    "        \n",
    "        # Extract state components\n",
    "        position = torch.tensor(state[\"position\"], dtype=torch.float32)\n",
    "        chips_collected = torch.tensor([state[\"player_collected_chips\"]], dtype=torch.float32)\n",
    "        total_chips_collected = torch.tensor([state[\"total_collected_chips\"]], dtype=torch.float32)\n",
    "        socket_unlocked = torch.tensor([int(state[\"socket_unlocked\"])], dtype=torch.float32)\n",
    "        nearest_chip = torch.tensor(state[\"nearest_chip\"], dtype=torch.float32)\n",
    "        exit_location = torch.tensor(state[\"exit_position\"], dtype=torch.float32)\n",
    "        \n",
    "        # Process the full grid\n",
    "        full_grid = []\n",
    "        for row in state[\"full_grid\"]:\n",
    "            processed_row = []\n",
    "            for tile_type in row:\n",
    "                # Map to integer using the updated tile definitions\n",
    "                processed_row.append(self.tile_type_to_id.get(tile_type, 1))\n",
    "            full_grid.append(processed_row)\n",
    "        \n",
    "        full_grid_tensor = torch.tensor(full_grid, dtype=torch.float32)\n",
    "        \n",
    "        local_grid = []\n",
    "        for row in state[\"local_grid\"]:\n",
    "            processed_row = []\n",
    "            for tile_type in row:\n",
    "                # Map to integer using the updated tile definitions\n",
    "                processed_row.append(self.tile_type_to_id.get(tile_type, 1))\n",
    "            local_grid.append(processed_row)\n",
    "        \n",
    "        local_grid_tensor = torch.tensor(local_grid, dtype=torch.float32)\n",
    "        \n",
    "        # Additional state information\n",
    "        alive = torch.tensor([float(state.get(\"alive\", True))], dtype=torch.float32)\n",
    "        remaining_chips = torch.tensor([state.get(\"remaining_chips\", 0)], dtype=torch.float32)\n",
    "        other_player_pos = torch.tensor(state.get(\"other_player_position\", [-1, -1]), dtype=torch.float32)\n",
    "        \n",
    "        # Concatenate all state information into a single vector\n",
    "        state_vector = torch.cat([\n",
    "            position,\n",
    "            chips_collected, \n",
    "            total_chips_collected,\n",
    "            socket_unlocked,\n",
    "            nearest_chip,\n",
    "            exit_location,\n",
    "            full_grid_tensor.flatten(),\n",
    "            local_grid_tensor.flatten(),\n",
    "            alive,\n",
    "            remaining_chips,\n",
    "            other_player_pos\n",
    "        ])\n",
    "        \n",
    "        return state_vector, torch.tensor(action, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Level2GameDataset(Dataset):\n",
    "    def __init__(self, json_file):\n",
    "        \"\"\"\n",
    "        Initialize the Level 2 Game Dataset with enhanced state representation\n",
    "        \n",
    "        Args:\n",
    "            json_file (str): Path to the JSON file containing gameplay data\n",
    "            transform (callable, optional): Optional transform to be applied on a sample\n",
    "        \"\"\"\n",
    "        # Load data\n",
    "        with open(json_file, \"r\") as f:\n",
    "            self.data = json.load(f)\n",
    "        \n",
    "        # Action to integer mapping\n",
    "        self.action_mapping = {\"UP\": 0, \"DOWN\": 1, \"LEFT\": 2, \"RIGHT\": 3}\n",
    "        \n",
    "        \n",
    "        # Process the TILE_MAPPING to build our encoding dictionary\n",
    "        self.tile_type_to_id = {}\n",
    "        for tile_id, (tile_type, _, _, _, _) in TILE_MAPPING.items():\n",
    "            self.tile_type_to_id[tile_type] = tile_id\n",
    "        \n",
    "        # Map for key and boot types\n",
    "        self.key_mapping = {\"RED\": 0, \"BLUE\": 1, \"YELLOW\": 2, \"GREEN\": 3}\n",
    "        self.boot_mapping = {\"WATER\": 0, \"FIRE\": 1, \"FORCE\": 2}\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get sample by index\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (state_vector, action)\n",
    "        \"\"\"\n",
    "        sample = self.data[idx]\n",
    "        state = sample[\"state\"]\n",
    "        action = self.action_mapping[sample[\"action\"]]\n",
    "        \n",
    "        # Extract base state information (similar to Level 1)\n",
    "        position = torch.tensor(state[\"position\"], dtype=torch.float32)\n",
    "        chips_collected = torch.tensor([state[\"player_collected_chips\"]], dtype=torch.float32)\n",
    "        total_chips_collected = torch.tensor([state[\"total_collected_chips\"]], dtype=torch.float32)\n",
    "        socket_unlocked = torch.tensor([int(state[\"socket_unlocked\"])], dtype=torch.float32)\n",
    "        nearest_chip = torch.tensor(state[\"nearest_chip\"], dtype=torch.float32)\n",
    "        nearest_key = torch.tensor(state[\"nearest_key\"], dtype=torch.float32)\n",
    "        nearest_boot = torch.tensor(state[\"nearest_boot\"], dtype=torch.float32)\n",
    "        exit_position = torch.tensor(state[\"exit_position\"], dtype=torch.float32)\n",
    "        \n",
    "        full_grid = []\n",
    "        for row in state[\"full_grid\"]:\n",
    "            processed_row = []\n",
    "            for tile_type in row:\n",
    "                # Map to integer using the updated tile definitions\n",
    "                processed_row.append(self.tile_type_to_id.get(tile_type, 1))\n",
    "            full_grid.append(processed_row)\n",
    "        \n",
    "        full_grid_tensor = torch.tensor(full_grid, dtype=torch.float32).flatten()\n",
    "        \n",
    "        # Extract local grid (decode type strings into integers)\n",
    "        # Level 2 may have a different local_grid structure\n",
    "        if isinstance(state[\"local_grid\"], list) and all(isinstance(item, int) for item in state[\"local_grid\"]):\n",
    "            # Already flattened encoded grid with integers\n",
    "            local_grid_tensor = torch.tensor(state[\"local_grid\"], dtype=torch.float32)\n",
    "        else:\n",
    "            # Handle traditional 2D grid of tile types\n",
    "            local_grid = []\n",
    "            for row in state[\"local_grid\"]:\n",
    "                grid_row = []\n",
    "                for tile_type in row:\n",
    "                    # Default to WALL if type not in mapping\n",
    "                    tile_value = self.tile_type_to_id.get(tile_type, 1)\n",
    "                    grid_row.append(tile_value)\n",
    "                local_grid.append(grid_row)\n",
    "            local_grid_tensor = torch.tensor(local_grid, dtype=torch.float32).flatten()\n",
    "            \n",
    "        # Enhanced state features for Level 2\n",
    "        # Player state\n",
    "        is_sliding = torch.tensor([int(state[\"is_sliding\"])], dtype=torch.float32)\n",
    "        is_being_forced = torch.tensor([int(state[\"is_being_forced\"])], dtype=torch.float32)\n",
    "        alive = torch.tensor([int(state[\"alive\"])], dtype=torch.float32)\n",
    "        \n",
    "        # Game state\n",
    "        remaining_chips = torch.tensor([state[\"remaining_chips\"]], dtype=torch.float32)\n",
    "        \n",
    "        # Multiplayer state\n",
    "        other_player_position = torch.tensor(state[\"other_player_position\"] if state[\"other_player_position\"] else [-1, -1], \n",
    "                                           dtype=torch.float32)\n",
    "        player_id = torch.tensor([state[\"player_id\"]], dtype=torch.float32)\n",
    "        \n",
    "        # Keys and boots (encode as one-hot vectors)\n",
    "        keys_tensor = torch.zeros(4, dtype=torch.float32)  # RED, BLUE, YELLOW, GREEN\n",
    "        if state[\"collected_keys\"]:\n",
    "            for key in state[\"collected_keys\"]:\n",
    "                if key in self.key_mapping:\n",
    "                    keys_tensor[self.key_mapping[key]] = 1\n",
    "                    \n",
    "        boots_tensor = torch.zeros(3, dtype=torch.float32)  # WATER, FIRE, FORCE\n",
    "        if state[\"collected_boots\"]:\n",
    "            for boot in state[\"collected_boots\"]:\n",
    "                if boot in self.boot_mapping:\n",
    "                    boots_tensor[self.boot_mapping[boot]] = 1\n",
    "    \n",
    "        # Time information\n",
    "        time_elapsed = torch.tensor([state[\"time_elapsed\"]/1000] if \"time_elapsed\" in state else [0], \n",
    "                                  dtype=torch.float32)  # Normalize to seconds\n",
    "        \n",
    "        # Goal position information\n",
    "        goal_pos = torch.tensor(state[\"goal_pos\"] if \"goal_pos\" in state else [-1, -1], \n",
    "                              dtype=torch.float32)\n",
    "        \n",
    "        # Other player information\n",
    "        other_player_chips = torch.tensor([state[\"other_player_collected_chips\"]] \n",
    "                                       if \"other_player_collected_chips\" in state else [0], \n",
    "                                       dtype=torch.float32)\n",
    "        \n",
    "        # Construct the full state vector by concatenating all features\n",
    "        state_vector = torch.cat([\n",
    "            # Base state (Level 1 compatible)\n",
    "            position, \n",
    "            chips_collected,\n",
    "            total_chips_collected, \n",
    "            socket_unlocked,\n",
    "            nearest_chip,\n",
    "            nearest_key,\n",
    "            nearest_boot,\n",
    "            exit_position,\n",
    "            full_grid_tensor,\n",
    "            local_grid_tensor,\n",
    "            \n",
    "            # Enhanced state (Level 2)\n",
    "            is_sliding,\n",
    "            is_being_forced,\n",
    "            alive,\n",
    "            remaining_chips,\n",
    "            other_player_position,\n",
    "            player_id,\n",
    "            keys_tensor,\n",
    "            boots_tensor,\n",
    "            time_elapsed,\n",
    "            goal_pos,\n",
    "            other_player_chips\n",
    "        ])\n",
    "            \n",
    "        return state_vector, torch.tensor(action, dtype=torch.long)\n",
    "    \n",
    "    def get_input_size(self):\n",
    "        \"\"\"Return the size of the state vector (useful for model initialization)\"\"\"\n",
    "        # Get a sample to determine vector size\n",
    "        sample_vector, _ = self[0]\n",
    "        return len(sample_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔢 Sample Vector: torch.Size([209])\n",
      "📊 Loaded 3842 samples.\n"
     ]
    }
   ],
   "source": [
    "dataset = Level2GameDataset(\"../data/human_play_data_level1.json\")\n",
    "\n",
    "# The rest of your code remains unchanged\n",
    "sample_vector, sample_action = dataset[0]\n",
    "print(f\"🔢 Sample Vector: {sample_vector.size()}\")\n",
    "print(f\"📊 Loaded {len(dataset)} samples.\")\n",
    "\n",
    "# Train your model as usual\n",
    "input_size = len(sample_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and validation\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "sub_train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(dataset, batch_size=64, shuffle=False, drop_last=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behavior Cloning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNC Network for behavior cloning\n",
    "class BehaviorCloningModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(BehaviorCloningModel, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),                    \n",
    "            nn.Linear(128, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FNC Network for behavior cloning\n",
    "class BehaviorCloningModelLv2(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(BehaviorCloningModelLv2, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_size),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_size 209, output_size: 4\n",
      "hidden_size Sequential(\n",
      "  (0): Linear(in_features=209, out_features=128, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=128, out_features=128, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=128, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "input_size = len(dataset[0][0])  # Size of State Vector\n",
    "output_size = 4  # Possible Actions (UP, DOWN, LEFT, RIGHT)\n",
    "model = BehaviorCloningModelLv2(input_size, output_size)\n",
    "print(f\"input_size {input_size}, output_size: {output_size}\")\n",
    "print(f\"hidden_size {model.fc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_config = {\n",
    "    \"epochs\": 300,\n",
    "    \"model_name\": \"BehaviorCloningModelLv2\",\n",
    "    \"input_size\": input_size,\n",
    "    \"output_size\": output_size,\n",
    "    \"optimizer\": \"Adam\",\n",
    "    \"learning_rate\": 0.001,\n",
    "    \"batch_size\": 64,\n",
    "    \"criterion\": \"CrossEntropyLoss\",\n",
    "    \"activation\": \"ReLU\",\n",
    "    \"scheduler\": \"ReduceLROnPlateau\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/neo/.netrc\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/neo/gym-workspace/2p_tworld/colab/wandb/run-20250312_050254-m780enjb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner_lv2/runs/m780enjb' target=\"_blank\">level1_run_9.4</a></strong> to <a href='https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner_lv2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner_lv2' target=\"_blank\">https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner_lv2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner_lv2/runs/m780enjb' target=\"_blank\">https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner_lv2/runs/m780enjb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"294ac5de6babc54da53b9aadb344b3bb173b314d\")\n",
    "# change name for each run\n",
    "wandb.init(project=\"bc_surrogate_partner_lv2\", name=\"level1_run_9.4\", config=training_config)\n",
    "wandb.config.update(training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/marlenv/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=training_config[\"learning_rate\"])\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=20, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/300, Train Loss: 0.2340, Train Acc: 89.48%, Val Loss: 0.2782, Val Acc: 87.26%, LR: 0.001000\n",
      "Epoch 20/300, Train Loss: 0.2101, Train Acc: 90.08%, Val Loss: 0.3185, Val Acc: 85.96%, LR: 0.001000\n",
      "Epoch 30/300, Train Loss: 0.2260, Train Acc: 89.56%, Val Loss: 0.2562, Val Acc: 88.04%, LR: 0.001000\n",
      "Epoch 40/300, Train Loss: 0.1693, Train Acc: 91.67%, Val Loss: 0.1973, Val Acc: 89.86%, LR: 0.000500\n",
      "Epoch 50/300, Train Loss: 0.1565, Train Acc: 92.01%, Val Loss: 0.2149, Val Acc: 89.60%, LR: 0.000500\n",
      "Epoch 60/300, Train Loss: 0.1667, Train Acc: 91.80%, Val Loss: 0.2068, Val Acc: 89.86%, LR: 0.000500\n",
      "Epoch 70/300, Train Loss: 0.1461, Train Acc: 92.37%, Val Loss: 0.1284, Val Acc: 93.63%, LR: 0.000250\n",
      "Epoch 80/300, Train Loss: 0.1438, Train Acc: 92.45%, Val Loss: 0.1402, Val Acc: 92.85%, LR: 0.000250\n",
      "Epoch 90/300, Train Loss: 0.1419, Train Acc: 92.37%, Val Loss: 0.1164, Val Acc: 93.24%, LR: 0.000250\n",
      "Epoch 100/300, Train Loss: 0.1416, Train Acc: 92.24%, Val Loss: 0.1291, Val Acc: 92.20%, LR: 0.000250\n",
      "Epoch 110/300, Train Loss: 0.1381, Train Acc: 92.66%, Val Loss: 0.1346, Val Acc: 94.28%, LR: 0.000250\n",
      "Epoch 120/300, Train Loss: 0.1359, Train Acc: 92.58%, Val Loss: 0.1115, Val Acc: 94.02%, LR: 0.000250\n",
      "Epoch 130/300, Train Loss: 0.1373, Train Acc: 92.60%, Val Loss: 0.1083, Val Acc: 94.67%, LR: 0.000250\n",
      "Epoch 140/300, Train Loss: 0.1279, Train Acc: 92.99%, Val Loss: 0.0993, Val Acc: 94.67%, LR: 0.000125\n",
      "Epoch 150/300, Train Loss: 0.1270, Train Acc: 92.92%, Val Loss: 0.1005, Val Acc: 94.67%, LR: 0.000125\n",
      "Epoch 160/300, Train Loss: 0.1266, Train Acc: 93.02%, Val Loss: 0.1411, Val Acc: 94.41%, LR: 0.000125\n",
      "Epoch 170/300, Train Loss: 0.1268, Train Acc: 92.89%, Val Loss: 0.0977, Val Acc: 95.32%, LR: 0.000125\n",
      "Epoch 180/300, Train Loss: 0.1268, Train Acc: 92.89%, Val Loss: 0.0982, Val Acc: 95.32%, LR: 0.000125\n",
      "Epoch 190/300, Train Loss: 0.1260, Train Acc: 92.94%, Val Loss: 0.0985, Val Acc: 94.80%, LR: 0.000125\n",
      "Epoch 200/300, Train Loss: 0.1277, Train Acc: 92.68%, Val Loss: 0.0992, Val Acc: 94.54%, LR: 0.000125\n",
      "Epoch 210/300, Train Loss: 0.1224, Train Acc: 93.20%, Val Loss: 0.1137, Val Acc: 94.80%, LR: 0.000063\n",
      "Epoch 220/300, Train Loss: 0.1221, Train Acc: 93.10%, Val Loss: 0.0971, Val Acc: 94.15%, LR: 0.000063\n",
      "Epoch 230/300, Train Loss: 0.1220, Train Acc: 93.15%, Val Loss: 0.0968, Val Acc: 94.28%, LR: 0.000063\n",
      "Epoch 240/300, Train Loss: 0.1218, Train Acc: 93.15%, Val Loss: 0.0964, Val Acc: 94.80%, LR: 0.000063\n",
      "Epoch 250/300, Train Loss: 0.1216, Train Acc: 93.28%, Val Loss: 0.0964, Val Acc: 95.06%, LR: 0.000063\n",
      "Epoch 260/300, Train Loss: 0.1215, Train Acc: 93.12%, Val Loss: 0.0971, Val Acc: 94.54%, LR: 0.000063\n",
      "Epoch 270/300, Train Loss: 0.1212, Train Acc: 93.18%, Val Loss: 0.1256, Val Acc: 94.41%, LR: 0.000063\n",
      "Epoch 280/300, Train Loss: 0.1210, Train Acc: 93.12%, Val Loss: 0.0969, Val Acc: 94.80%, LR: 0.000063\n",
      "Epoch 290/300, Train Loss: 0.1196, Train Acc: 93.44%, Val Loss: 0.0954, Val Acc: 94.80%, LR: 0.000031\n",
      "Epoch 300/300, Train Loss: 0.1194, Train Acc: 93.33%, Val Loss: 0.0952, Val Acc: 94.41%, LR: 0.000031\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▄▄▅▅▅▅▅▆▆▆▇▇▇▇▇▇▇██</td></tr><tr><td>learning_rate</td><td>█████▄▄▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_accuracy</td><td>▁▅▅▄▄▅▄▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇▇█▇██████████</td></tr><tr><td>train_loss</td><td>█▇▇▇▆▃▃▅▄▃▃▃▃▃▃▃▂▂▂▂▂▂▁▁▂▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▄▅▆▆▆▇▇▇██▇███▇██████████████████████</td></tr><tr><td>val_loss</td><td>█▂▃▄▂▂▂▂▂▂▂▁▁▁▁▁▂▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>300</td></tr><tr><td>learning_rate</td><td>3e-05</td></tr><tr><td>train_accuracy</td><td>93.33333</td></tr><tr><td>train_loss</td><td>0.11939</td></tr><tr><td>val_accuracy</td><td>94.40832</td></tr><tr><td>val_loss</td><td>0.09524</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">level1_run_9.4</strong> at: <a href='https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner_lv2/runs/m780enjb' target=\"_blank\">https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner_lv2/runs/m780enjb</a><br> View project at: <a href='https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner_lv2' target=\"_blank\">https://wandb.ai/knocknocknik-pitts/bc_surrogate_partner_lv2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250312_050254-m780enjb/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(training_config[\"epochs\"]):\n",
    "    # Training phase\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for state_vectors, actions in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(state_vectors)\n",
    "        loss = criterion(outputs, actions)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        train_total += actions.size(0)\n",
    "        train_correct += (predicted == actions).sum().item()\n",
    "    \n",
    "    train_loss = train_loss / len(train_loader)\n",
    "    train_accuracy = 100 * train_correct / train_total\n",
    "    \n",
    "    # Validation phase\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for state_vectors, actions in val_loader:\n",
    "            outputs = model(state_vectors)\n",
    "            loss = criterion(outputs, actions)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            val_total += actions.size(0)\n",
    "            val_correct += (predicted == actions).sum().item()\n",
    "    \n",
    "    val_loss = val_loss / len(val_loader)\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Log metrics\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": train_loss,\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"val_loss\": val_loss,\n",
    "        \"val_accuracy\": val_accuracy,\n",
    "        \"learning_rate\": optimizer.param_groups[0][\"lr\"]\n",
    "    })\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{training_config['epochs']}, \"\n",
    "              f\"Train Loss: {train_loss:.4f}, Train Acc: {train_accuracy:.2f}%, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%, \"\n",
    "              f\"LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "# Close wandb\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../model/lv2_bc_model_9.4.pth\n"
     ]
    }
   ],
   "source": [
    "# Model save directory\n",
    "model_path = \"../model/lv2_bc_model_9.4.pth\"\n",
    "# Save model\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(\"Model saved to \" + model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Predicted Action: DOWN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jk/fgtqjbt14jg00g8k4jkjl6_40000gn/T/ipykernel_88944/3803181024.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  state_vector = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n"
     ]
    }
   ],
   "source": [
    "def predict_action(model, state):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        state_vector = torch.tensor(state, dtype=torch.float32).unsqueeze(0)\n",
    "        output = model(state_vector)\n",
    "        action_idx = torch.argmax(output).item()\n",
    "    \n",
    "    action_mapping = {0: \"UP\", 1: \"DOWN\", 2: \"LEFT\", 3: \"RIGHT\"}\n",
    "    return action_mapping[action_idx]\n",
    "\n",
    "test_state, _ = dataset[5]  # Check the first sample in the dataset\n",
    "predicted_action = predict_action(model, test_state)\n",
    "print(f\"AI Predicted Action: {predicted_action}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
